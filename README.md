# BÃ i táº­p 01 - XÃ¢y dá»±ng Pipeline Machine Learning

## ğŸ“‹ ThÃ´ng tin chung

**Má»¥c tiÃªu**: XÃ¢y dá»±ng pipeline hoÃ n chá»‰nh Ä‘á»ƒ phÃ¢n loáº¡i cháº¥t lÆ°á»£ng káº¿t ná»‘i RF (RF Link Quality) tá»« dá»¯ liá»‡u truyá»n thÃ´ng khÃ´ng dÃ¢y.

**Dataset**: `wireless_communication_dataset.csv`

**File thá»±c hiá»‡n**: `nhom_01_BT01.ipynb`
---

## ğŸ¯ YÃªu cáº§u bÃ i táº­p

1. âœ… XÃ¢y dá»±ng Pipeline duy nháº¥t xá»­ lÃ½ toÃ n bá»™ dá»¯ liá»‡u
2. âœ… Sá»­ dá»¥ng ColumnTransformer Ä‘á»ƒ xá»­ lÃ½ riÃªng biá»‡t:
   - Cá»™t sá»‘ (numeric): StandardScaler
   - Cá»™t phÃ¢n loáº¡i (categorical): OneHotEncoder
3. âœ… MÃ´ hÃ¬nh phÃ¢n loáº¡i: DecisionTreeClassifier hoáº·c KNeighborsClassifier
4. âœ… Chia dá»¯ liá»‡u 80% train, 20% test
5. âœ… BÃ¡o cÃ¡o Accuracy vÃ  F1-Score trÃªn táº­p test

---

## ğŸ“Š Tá»•ng quan vá» Dataset

### ThÃ´ng tin dá»¯ liá»‡u
- **Sá»‘ lÆ°á»£ng máº«u**: 5000 hÃ ng
- **Sá»‘ lÆ°á»£ng features**: 17 cá»™t
- **Biáº¿n má»¥c tiÃªu**: `RF Link Quality` (Poor, Moderate, Good, 0)

### CÃ¡c cá»™t trong dataset

#### 1. Cá»™t sá»‘ (Numeric Features) - 15 cá»™t:
1. `User Speed (m/s)` - Tá»‘c Ä‘á»™ ngÆ°á»i dÃ¹ng
2. `User Direction (degrees)` - HÆ°á»›ng di chuyá»ƒn
3. `Handover Events` - Sá»‘ láº§n chuyá»ƒn giao
4. `Distance from Base Station (m)` - Khoáº£ng cÃ¡ch tá»« tráº¡m gá»‘c
5. `Signal Strength (dBm)` - CÆ°á»ng Ä‘á»™ tÃ­n hiá»‡u
6. `SNR (dB)` - Tá»· lá»‡ tÃ­n hiá»‡u trÃªn nhiá»…u
7. `BER` - Tá»· lá»‡ lá»—i bit
8. `PDR (%)` - Tá»· lá»‡ gÃ³i tin Ä‘Æ°á»£c gá»­i
9. `Throughput (Mbps)` - BÄƒng thÃ´ng
10. `Latency (ms)` - Äá»™ trá»…
11. `Retransmission Count` - Sá»‘ láº§n truyá»n láº¡i
12. `Power Consumption (mW)` - TiÃªu thá»¥ nÄƒng lÆ°á»£ng
13. `Battery Level (%)` - Má»©c pin
14. `Transmission Power (dBm)` - CÃ´ng suáº¥t truyá»n
15. `Network Congestion` - Má»©c Ä‘á»™ táº¯c ngháº½n máº¡ng (cÃ³ thá»ƒ lÃ  categorical)

#### 2. Cá»™t phÃ¢n loáº¡i (Categorical Features) - 2 cá»™t:
1. `Modulation Scheme` - SÆ¡ Ä‘á»“ Ä‘iá»u cháº¿ (BPSK, QPSK, 16-QAM, 64-QAM)
2. `Network Congestion` - Táº¯c ngháº½n máº¡ng (Low, Medium, High)

#### 3. Biáº¿n má»¥c tiÃªu (Target):
- `RF Link Quality` - Cháº¥t lÆ°á»£ng káº¿t ná»‘i RF (Poor, Moderate, Good, 0)

---

## ğŸ” Quy trÃ¬nh thá»±c hiá»‡n chi tiáº¿t

### **BÆ°á»›c 1: Import thÆ° viá»‡n** 

#### Má»¥c Ä‘Ã­ch:
Chuáº©n bá»‹ cÃ¡c cÃ´ng cá»¥ cáº§n thiáº¿t Ä‘á»ƒ xá»­ lÃ½ dá»¯ liá»‡u, xÃ¢y dá»±ng pipeline vÃ  Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh.

#### ThÆ° viá»‡n sá»­ dá»¥ng:
```python
import pandas as pd                    # Xá»­ lÃ½ dá»¯ liá»‡u dáº¡ng báº£ng
import numpy as np                     # TÃ­nh toÃ¡n sá»‘ há»c
import matplotlib.pyplot as plt        # Váº½ biá»ƒu Ä‘á»“
import seaborn as sns                  # Trá»±c quan hÃ³a dá»¯ liá»‡u nÃ¢ng cao

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix
```

#### Kiáº¿n thá»©c liÃªn quan:
- **Pandas**: ThÆ° viá»‡n xá»­ lÃ½ dá»¯ liá»‡u dáº¡ng DataFrame
- **Scikit-learn**: ThÆ° viá»‡n Machine Learning phá»• biáº¿n nháº¥t Python
- **Matplotlib/Seaborn**: ThÆ° viá»‡n trá»±c quan hÃ³a dá»¯ liá»‡u

---

### **BÆ°á»›c 2: Táº£i vÃ  khÃ¡m phÃ¡ dá»¯ liá»‡u (Exploratory Data Analysis - EDA)**

#### 2.1 Äá»c dá»¯ liá»‡u
```python
df = pd.read_csv('wireless_communication_dataset.csv')
```

#### 2.2 Kiá»ƒm tra thÃ´ng tin cÆ¡ báº£n
- **Shape**: KÃ­ch thÆ°á»›c dá»¯ liá»‡u (sá»‘ hÃ ng Ã— sá»‘ cá»™t)
- **Info**: Kiá»ƒu dá»¯ liá»‡u cá»§a tá»«ng cá»™t, sá»‘ lÆ°á»£ng non-null values
- **Describe**: Thá»‘ng kÃª mÃ´ táº£ (mean, std, min, max, quartiles)
- **Head/Tail**: Xem má»™t sá»‘ hÃ ng Ä‘áº§u/cuá»‘i

#### 2.3 Kiá»ƒm tra giÃ¡ trá»‹ thiáº¿u
```python
df.isnull().sum()
```
**Káº¿t quáº£**: KhÃ´ng cÃ³ giÃ¡ trá»‹ thiáº¿u trong dataset

#### 2.4 PhÃ¢n tÃ­ch biáº¿n má»¥c tiÃªu
```python
df['RF Link Quality'].value_counts()
```
- XÃ¡c Ä‘á»‹nh sá»‘ lÆ°á»£ng máº«u trong tá»«ng lá»›p
- Kiá»ƒm tra sá»± cÃ¢n báº±ng/máº¥t cÃ¢n báº±ng cá»§a dá»¯ liá»‡u
- PhÃ¡t hiá»‡n giÃ¡ trá»‹ '0' (unknown/undefined) cáº§n xá»­ lÃ½

#### Kiáº¿n thá»©c liÃªn quan:
- **EDA**: QuÃ¡ trÃ¬nh khÃ¡m phÃ¡, hiá»ƒu rÃµ dá»¯ liá»‡u trÆ°á»›c khi xÃ¢y dá»±ng mÃ´ hÃ¬nh
- **Missing values**: GiÃ¡ trá»‹ thiáº¿u cÃ³ thá»ƒ áº£nh hÆ°á»Ÿng Ä‘áº¿n cháº¥t lÆ°á»£ng mÃ´ hÃ¬nh
- **Class imbalance**: Sá»± máº¥t cÃ¢n báº±ng giá»¯a cÃ¡c lá»›p cÃ³ thá»ƒ lÃ m mÃ´ hÃ¬nh thiÃªn vá»‹

---

### **BÆ°á»›c 3: PhÃ¢n tÃ­ch vÃ  xÃ¡c Ä‘á»‹nh loáº¡i cá»™t**

#### 3.1 Tá»± Ä‘á»™ng phÃ¢n loáº¡i cá»™t
```python
numeric_features = df.select_dtypes(include=['int64', 'float64']).columns.tolist()
categorical_features = df.select_dtypes(include=['object']).columns.tolist()
```

#### 3.2 Loáº¡i bá» cá»™t má»¥c tiÃªu khá»i features
```python
if target_column in categorical_features:
    categorical_features.remove(target_column)
```

#### 3.3 Káº¿t quáº£ phÃ¢n loáº¡i
- **15 cá»™t sá»‘**: CÃ¡c Ä‘áº·c trÆ°ng liÃªn tá»¥c (continuous)
- **2 cá»™t phÃ¢n loáº¡i**: Modulation Scheme, Network Congestion
- **1 cá»™t má»¥c tiÃªu**: RF Link Quality

#### Kiáº¿n thá»©c liÃªn quan:
- **Feature types**:
  - **Numeric**: Dá»¯ liá»‡u sá»‘ (continuous hoáº·c discrete)
  - **Categorical**: Dá»¯ liá»‡u phÃ¢n loáº¡i (nominal hoáº·c ordinal)
- **Feature engineering**: Viá»‡c xá»­ lÃ½ khÃ¡c nhau cho tá»«ng loáº¡i features

---

### **BÆ°á»›c 4: Trá»±c quan hÃ³a dá»¯ liá»‡u**

#### 4.1 Biá»ƒu Ä‘á»“ phÃ¢n phá»‘i biáº¿n má»¥c tiÃªu
```python
df['RF Link Quality'].value_counts().plot(kind='bar')
```
**Má»¥c Ä‘Ã­ch**: Hiá»ƒu rÃµ phÃ¢n phá»‘i cÃ¡c lá»›p trong dataset

#### 4.2 Ma tráº­n tÆ°Æ¡ng quan (Correlation Matrix)
```python
correlation_matrix = df[numeric_features].corr()
sns.heatmap(correlation_matrix, annot=True)
```

**Má»¥c Ä‘Ã­ch**: 
- PhÃ¡t hiá»‡n má»‘i quan há»‡ tuyáº¿n tÃ­nh giá»¯a cÃ¡c biáº¿n
- XÃ¡c Ä‘á»‹nh multicollinearity (Ä‘a cá»™ng tuyáº¿n)
- Loáº¡i bá» features dÆ° thá»«a náº¿u cáº§n

#### Kiáº¿n thá»©c liÃªn quan:
- **Correlation**: Äo lÆ°á»ng má»‘i quan há»‡ tuyáº¿n tÃ­nh (-1 Ä‘áº¿n +1)
- **Heatmap**: Biá»ƒu Ä‘á»“ nhiá»‡t thá»ƒ hiá»‡n correlation matrix
- **Feature selection**: Chá»n features quan trá»ng, loáº¡i bá» features khÃ´ng cáº§n thiáº¿t

---

### **BÆ°á»›c 5: Chuáº©n bá»‹ dá»¯ liá»‡u (Data Preparation)**

#### 5.1 Xá»­ lÃ½ dá»¯ liá»‡u nhiá»…u
```python
df_cleaned = df[df['RF Link Quality'] != '0'].copy()
```
**LÃ½ do**: Loáº¡i bá» cÃ¡c máº«u cÃ³ nhÃ£n '0' (khÃ´ng xÃ¡c Ä‘á»‹nh/khÃ´ng há»£p lá»‡)

#### 5.2 TÃ¡ch features vÃ  target
```python
X = df_cleaned.drop(columns=[target_column])
y = df_cleaned[target_column]
```

#### 5.3 Chia dá»¯ liá»‡u Train/Test (80/20)
```python
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)
```

**Tham sá»‘ quan trá»ng**:
- `test_size=0.2`: 20% dá»¯ liá»‡u cho test set
- `random_state=42`: Äáº£m báº£o káº¿t quáº£ cÃ³ thá»ƒ tÃ¡i táº¡o
- `stratify=y`: Giá»¯ nguyÃªn tá»· lá»‡ cÃ¡c lá»›p trong train vÃ  test set

#### Kiáº¿n thá»©c liÃªn quan:
- **Train/Test split**: TrÃ¡nh overfitting, Ä‘Ã¡nh giÃ¡ khÃ¡ch quan
- **Stratified sampling**: Quan trá»ng vá»›i dá»¯ liá»‡u khÃ´ng cÃ¢n báº±ng
- **Random state**: Äáº£m báº£o reproducibility trong nghiÃªn cá»©u

---

### **BÆ°á»›c 6: XÃ¢y dá»±ng Pipeline vá»›i ColumnTransformer** â­

#### 6.1 KhÃ¡i niá»‡m Pipeline
**Pipeline** lÃ  má»™t cÃ´ng cá»¥ trong Scikit-learn cho phÃ©p:
- Káº¿t há»£p nhiá»u bÆ°á»›c xá»­ lÃ½ dá»¯ liá»‡u thÃ nh má»™t chuá»—i
- Äáº£m báº£o cÃ¡c bÆ°á»›c Ä‘Æ°á»£c thá»±c hiá»‡n theo Ä‘Ãºng thá»© tá»±
- TrÃ¡nh data leakage giá»¯a train vÃ  test set
- Code gá»n gÃ ng, dá»… báº£o trÃ¬

#### 6.2 ColumnTransformer - Xá»­ lÃ½ riÃªng biá»‡t cÃ¡c loáº¡i cá»™t

```python
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numeric_features),
        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)
    ],
    remainder='passthrough'
)
```

**Giáº£i thÃ­ch**:
- **StandardScaler** cho cá»™t sá»‘:
  - Chuáº©n hÃ³a dá»¯ liá»‡u vá» mean=0, std=1
  - CÃ´ng thá»©c: `z = (x - Î¼) / Ïƒ`
  - Quan trá»ng cho KNN vÃ  cÃ¡c thuáº­t toÃ¡n dá»±a trÃªn khoáº£ng cÃ¡ch
  
- **OneHotEncoder** cho cá»™t phÃ¢n loáº¡i:
  - Chuyá»ƒn categorical thÃ nh binary vectors
  - VÃ­ dá»¥: ['Low', 'Medium', 'High'] â†’ [[1,0,0], [0,1,0], [0,0,1]]
  - `handle_unknown='ignore'`: Xá»­ lÃ½ giÃ¡ trá»‹ má»›i chÆ°a gáº·p trong training

#### 6.3 Táº¡o Pipeline hoÃ n chá»‰nh

```python
pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', DecisionTreeClassifier(...))
])
```

**Æ¯u Ä‘iá»ƒm Pipeline**:
1. âœ… Tá»± Ä‘á»™ng apply cÃ¡c bÆ°á»›c preprocessing cho cáº£ train vÃ  test
2. âœ… TrÃ¡nh data leakage (fit_transform trÃªn train, transform trÃªn test)
3. âœ… Dá»… dÃ ng thay Ä‘á»•i vÃ  thá»­ nghiá»‡m cÃ¡c thuáº­t toÃ¡n khÃ¡c nhau
4. âœ… CÃ³ thá»ƒ lÆ°u vÃ  tÃ¡i sá»­ dá»¥ng toÃ n bá»™ pipeline

#### Kiáº¿n thá»©c liÃªn quan:
- **Feature scaling**: Chuáº©n hÃ³a Ä‘á»ƒ cÃ¡c features cÃ³ táº§m áº£nh hÆ°á»Ÿng tÆ°Æ¡ng Ä‘Æ°Æ¡ng
- **One-hot encoding**: Biáº¿n Ä‘á»•i categorical thÃ nh numeric
- **Data leakage**: Lá»—i nghiÃªm trá»ng khi thÃ´ng tin tá»« test "rÃ² rá»‰" vÃ o train
- **Pipeline pattern**: Design pattern quan trá»ng trong ML

---

### **BÆ°á»›c 7: Huáº¥n luyá»‡n vÃ  Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh**

#### 7.1 DecisionTreeClassifier

**Thuáº­t toÃ¡n**:
- CÃ¢y quyáº¿t Ä‘á»‹nh phÃ¢n loáº¡i dá»±a trÃªn viá»‡c chia dá»¯ liá»‡u theo cÃ¡c Ä‘iá»u kiá»‡n
- Má»—i node lÃ  má»™t Ä‘iá»u kiá»‡n kiá»ƒm tra (if-else)
- Leaf nodes chá»©a káº¿t quáº£ phÃ¢n loáº¡i

**Hyperparameters**:
```python
DecisionTreeClassifier(
    random_state=42,        # Reproducibility
    max_depth=10,           # Äá»™ sÃ¢u tá»‘i Ä‘a cá»§a cÃ¢y (trÃ¡nh overfitting)
    min_samples_split=10    # Sá»‘ máº«u tá»‘i thiá»ƒu Ä‘á»ƒ chia node
)
```

**Æ¯u Ä‘iá»ƒm**:
- Dá»… hiá»ƒu, dá»… visualize
- KhÃ´ng cáº§n feature scaling
- Xá»­ lÃ½ Ä‘Æ°á»£c cáº£ numeric vÃ  categorical
- CÃ³ thá»ƒ há»c non-linear relationships

**NhÆ°á»£c Ä‘iá»ƒm**:
- Dá»… overfit
- KhÃ´ng á»•n Ä‘á»‹nh (nháº¡y cáº£m vá»›i thay Ä‘á»•i dá»¯ liá»‡u)
- KhÃ´ng tá»‘t vá»›i dá»¯ liá»‡u cÃ³ nhiá»u chiá»u

#### 7.2 KNeighborsClassifier

**Thuáº­t toÃ¡n**:
- PhÃ¢n loáº¡i dá»±a trÃªn K lÃ¡ng giá»ng gáº§n nháº¥t
- TÃ­nh khoáº£ng cÃ¡ch tá»« Ä‘iá»ƒm test Ä‘áº¿n táº¥t cáº£ Ä‘iá»ƒm train
- Láº¥y majority vote tá»« K lÃ¡ng giá»ng

**Hyperparameters**:
```python
KNeighborsClassifier(
    n_neighbors=5,      # Sá»‘ lÃ¡ng giá»ng xÃ©t Ä‘áº¿n
    weights='distance'  # LÃ¡ng giá»ng gáº§n hÆ¡n cÃ³ trá»ng sá»‘ lá»›n hÆ¡n
)
```

**Æ¯u Ä‘iá»ƒm**:
- ÄÆ¡n giáº£n, dá»… implement
- KhÃ´ng cÃ³ training phase (lazy learning)
- Hiá»‡u quáº£ vá»›i dá»¯ liá»‡u nhá»

**NhÆ°á»£c Ä‘iá»ƒm**:
- Cháº­m vá»›i dá»¯ liá»‡u lá»›n (pháº£i tÃ­nh khoáº£ng cÃ¡ch Ä‘áº¿n táº¥t cáº£ Ä‘iá»ƒm)
- Nháº¡y cáº£m vá»›i scaling vÃ  outliers
- Curse of dimensionality (khÃ´ng tá»‘t vá»›i nhiá»u features)

#### 7.3 Huáº¥n luyá»‡n
```python
pipeline.fit(X_train, y_train)
```
**QuÃ¡ trÃ¬nh**:
1. Fit StandardScaler trÃªn X_train (numeric)
2. Fit OneHotEncoder trÃªn X_train (categorical)
3. Transform X_train báº±ng fitted transformers
4. Fit classifier trÃªn transformed data

#### 7.4 Dá»± Ä‘oÃ¡n
```python
y_pred = pipeline.predict(X_test)
```
**QuÃ¡ trÃ¬nh**:
1. Transform X_test (khÃ´ng fit láº¡i!)
2. Dá»± Ä‘oÃ¡n báº±ng fitted classifier

---

### **BÆ°á»›c 8: ÄÃ¡nh giÃ¡ hiá»‡u suáº¥t mÃ´ hÃ¬nh**

#### 8.1 CÃ¡c metrics sá»­ dá»¥ng

**1. Accuracy (Äá»™ chÃ­nh xÃ¡c)**
```python
accuracy = accuracy_score(y_test, y_pred)
```
- CÃ´ng thá»©c: `Accuracy = (TP + TN) / (TP + TN + FP + FN)`
- Tá»· lá»‡ dá»± Ä‘oÃ¡n Ä‘Ãºng trÃªn tá»•ng sá»‘ máº«u
- **Háº¡n cháº¿**: KhÃ´ng phÃ¹ há»£p vá»›i dá»¯ liá»‡u máº¥t cÃ¢n báº±ng

**2. F1-Score (weighted)**
```python
f1 = f1_score(y_test, y_pred, average='weighted')
```
- CÃ´ng thá»©c: `F1 = 2 Ã— (Precision Ã— Recall) / (Precision + Recall)`
- `weighted`: TÃ­nh F1 cho tá»«ng class, sau Ä‘Ã³ láº¥y trung bÃ¬nh cÃ³ trá»ng sá»‘
- CÃ¢n báº±ng giá»¯a Precision vÃ  Recall
- **Tá»‘t hÆ¡n Accuracy** vá»›i dá»¯ liá»‡u khÃ´ng cÃ¢n báº±ng

**3. Classification Report**
```python
classification_report(y_test, y_pred)
```
- BÃ¡o cÃ¡o chi tiáº¿t cho tá»«ng class:
  - **Precision**: Äá»™ chÃ­nh xÃ¡c cá»§a dá»± Ä‘oÃ¡n positive
  - **Recall**: Tá»· lá»‡ phÃ¡t hiá»‡n Ä‘Æ°á»£c positive thá»±c táº¿
  - **F1-Score**: Trung bÃ¬nh Ä‘iá»u hÃ²a cá»§a Precision vÃ  Recall
  - **Support**: Sá»‘ máº«u thá»±c táº¿ cá»§a má»—i class

**4. Confusion Matrix (Ma tráº­n nháº§m láº«n)**
```python
confusion_matrix(y_test, y_pred)
```
- Ma tráº­n hiá»ƒn thá»‹ sá»‘ lÆ°á»£ng dá»± Ä‘oÃ¡n Ä‘Ãºng/sai cho má»—i class
- Trá»¥c dá»c: True label
- Trá»¥c ngang: Predicted label
- Diagonal: Dá»± Ä‘oÃ¡n Ä‘Ãºng

#### 8.2 Trá»±c quan hÃ³a káº¿t quáº£

**Heatmap cá»§a Confusion Matrix**:
```python
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
```
- Dá»… nhÃ¬n tháº¥y pattern dá»± Ä‘oÃ¡n sai
- XÃ¡c Ä‘á»‹nh class nÃ o bá»‹ nháº§m láº«n nhiá»u

**Bar chart so sÃ¡nh**:
- So sÃ¡nh Accuracy giá»¯a cÃ¡c mÃ´ hÃ¬nh
- So sÃ¡nh F1-Score giá»¯a cÃ¡c mÃ´ hÃ¬nh

---

### **BÆ°á»›c 9: So sÃ¡nh vÃ  lá»±a chá»n mÃ´ hÃ¬nh**

#### 9.1 TiÃªu chÃ­ Ä‘Ã¡nh giÃ¡
1. **Accuracy**: Äá»™ chÃ­nh xÃ¡c tá»•ng thá»ƒ
2. **F1-Score**: CÃ¢n báº±ng Precision-Recall
3. **Training time**: Thá»i gian huáº¥n luyá»‡n
4. **Prediction time**: Thá»i gian dá»± Ä‘oÃ¡n
5. **Interpretability**: Kháº£ nÄƒng giáº£i thÃ­ch

#### 9.2 Trade-offs
- **Decision Tree**: Nhanh, dá»… hiá»ƒu, dá»… overfit
- **KNN**: ÄÆ¡n giáº£n, cháº­m khi predict, nháº¡y scaling

#### 9.3 Lá»±a chá»n mÃ´ hÃ¬nh tá»‘t nháº¥t
```python
best_model = 'Decision Tree' if accuracy_dt > accuracy_knn else 'K-Neighbors'
```

---

### **BÆ°á»›c 10: LÆ°u mÃ´ hÃ¬nh (Model Persistence)**

```python
import joblib
joblib.dump(best_pipeline, 'best_model.pkl')
```

**LÃ½ do cáº§n lÆ°u mÃ´ hÃ¬nh**:
- Sá»­ dá»¥ng láº¡i mÃ  khÃ´ng cáº§n train láº¡i
- Deploy vÃ o production
- Chia sáº» vá»›i ngÆ°á»i khÃ¡c

**Load mÃ´ hÃ¬nh**:
```python
loaded_model = joblib.load('best_model.pkl')
predictions = loaded_model.predict(new_data)
```

---

## ğŸ“š Kiáº¿n thá»©c quan trá»ng Ä‘Ã£ há»c

### 1. **Pipeline vÃ  ColumnTransformer**
- XÃ¢y dá»±ng quy trÃ¬nh ML hoÃ n chá»‰nh
- Xá»­ lÃ½ riÃªng biá»‡t cho tá»«ng loáº¡i features
- TrÃ¡nh data leakage

### 2. **Feature Preprocessing**
- **StandardScaler**: Chuáº©n hÃ³a cho numeric features
- **OneHotEncoder**: MÃ£ hÃ³a cho categorical features
- Táº§m quan trá»ng cá»§a feature scaling

### 3. **Classification Algorithms**
- **Decision Tree**: Thuáº­t toÃ¡n dá»±a trÃªn cÃ¢y quyáº¿t Ä‘á»‹nh
- **K-Neighbors**: Thuáº­t toÃ¡n dá»±a trÃªn khoáº£ng cÃ¡ch
- Æ¯u nhÆ°á»£c Ä‘iá»ƒm cá»§a tá»«ng thuáº­t toÃ¡n

### 4. **Model Evaluation**
- Accuracy, Precision, Recall, F1-Score
- Confusion Matrix
- Classification Report
- Táº§m quan trá»ng cá»§a viá»‡c chá»n metric phÃ¹ há»£p

### 5. **Best Practices**
- Train/Test split vá»›i stratify
- Random state Ä‘á»ƒ reproducibility
- Pipeline Ä‘á»ƒ code gá»n gÃ ng
- EDA trÆ°á»›c khi modeling

---

## ğŸ”§ Cáº£i thiá»‡n mÃ´ hÃ¬nh (Future Work)

### 1. **Hyperparameter Tuning**
```python
from sklearn.model_selection import GridSearchCV

param_grid = {
    'classifier__max_depth': [5, 10, 15, 20],
    'classifier__min_samples_split': [5, 10, 20]
}

grid_search = GridSearchCV(pipeline_dt, param_grid, cv=5)
grid_search.fit(X_train, y_train)
```

### 2. **Cross-Validation**
```python
from sklearn.model_selection import cross_val_score

scores = cross_val_score(pipeline, X_train, y_train, cv=5)
print(f"CV Accuracy: {scores.mean():.4f} (+/- {scores.std():.4f})")
```

### 3. **Feature Engineering**
- Táº¡o features má»›i tá»« features hiá»‡n cÃ³
- Feature selection (loáº¡i bá» features khÃ´ng quan trá»ng)
- Polynomial features

### 4. **Ensemble Methods**
- Random Forest (cáº£i tiáº¿n cá»§a Decision Tree)
- Gradient Boosting (XGBoost, LightGBM)
- Voting Classifier (káº¿t há»£p nhiá»u mÃ´ hÃ¬nh)

### 5. **Xá»­ lÃ½ Class Imbalance**
- SMOTE (Synthetic Minority Over-sampling)
- Class weights
- Undersampling/Oversampling

---


## ğŸ’¡ Tips vÃ  LÆ°u Ã½

### âœ… Do's (NÃªn lÃ m)
1. **LuÃ´n chia dá»¯ liá»‡u Train/Test** trÆ°á»›c khi lÃ m báº¥t cá»© Ä‘iá»u gÃ¬
2. **Sá»­ dá»¥ng Pipeline** Ä‘á»ƒ Ä‘áº£m báº£o quy trÃ¬nh nháº¥t quÃ¡n
3. **Stratify** khi split vá»›i classification problems
4. **Set random_state** Ä‘á»ƒ reproducibility
5. **EDA ká»¹ lÆ°á»¡ng** trÆ°á»›c khi modeling
6. **Evaluate trÃªn nhiá»u metrics**, khÃ´ng chá»‰ Accuracy
7. **Visualize** confusion matrix Ä‘á»ƒ hiá»ƒu rÃµ lá»—i

### âŒ Don'ts (KhÃ´ng nÃªn lÃ m)
1. **KhÃ´ng fit scaler trÃªn cáº£ dataset** (pháº£i fit riÃªng trÃªn train)
2. **KhÃ´ng bá» qua EDA** vÃ  Ä‘i tháº³ng vÃ o modeling
3. **KhÃ´ng chá»‰ dá»±a vÃ o Accuracy** vá»›i imbalanced data
4. **KhÃ´ng overfit** báº±ng cÃ¡ch tune quÃ¡ nhiá»u trÃªn test set
5. **KhÃ´ng quÃªn handle categorical features** Ä‘Ãºng cÃ¡ch
6. **KhÃ´ng bá» qua missing values** vÃ  outliers

---

## ğŸ“ Káº¿t luáº­n

BÃ i táº­p nÃ y Ä‘Ã£ giÃºp náº¯m vá»¯ng:
- âœ… Quy trÃ¬nh hoÃ n chá»‰nh cá»§a má»™t ML project
- âœ… Sá»­ dá»¥ng Pipeline vÃ  ColumnTransformer hiá»‡u quáº£
- âœ… Preprocessing khÃ¡c nhau cho tá»«ng loáº¡i features
- âœ… So sÃ¡nh vÃ  Ä‘Ã¡nh giÃ¡ nhiá»u mÃ´ hÃ¬nh
- âœ… Best practices trong Machine Learning

**Ká»¹ nÄƒng Ä‘áº¡t Ä‘Æ°á»£c**:
1. Data preprocessing vÃ  feature engineering
2. Building ML pipelines
3. Model training vÃ  evaluation
4. Model comparison vÃ  selection
5. Code organization vÃ  documentation

---


**NgÃ y hoÃ n thÃ nh**: November 22, 2025

**PhiÃªn báº£n**: 1.0

**TÃ¡c giáº£**: NhÃ³m 01
#   X - y - d - n g - P i p e l i n e - p h - n - l o - i - c h - t - l - n g - m - n g 
 
 